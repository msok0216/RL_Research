{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e41f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from data_processing import sort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338dcf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for i in range(1, 10):\n",
    "    path = \"./data/TEST_Kim-Study{i}.csv\".format(i=i)\n",
    "    temp = pd.read_csv(path)\n",
    "    files.append(temp[['Speaker','Dialogue State','IDE State']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11f29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDEMap = {'D7': 'D6D15', 'D8': 'D6D15', 'E3': 'D10', 'E1': 'D11', 'E2': 'D13', 'D18': 'D6D15D17', 'D19': 'D1D2',\n",
    "         'D21': 'D3D2', 'D22': 'D3D1', 'D23': 'D3D17', 'D25': 'D1D2D9', 'D27': 'DD3D17D1', 'D28': 'D5', 'D29': 'D17D14',\n",
    "         'D30': 'D6', 'D31': 'D5D2', 'D32': 'D10', 'D33': 'D6', 'D34': 'D16D1', 'D36': 'D17D16', 'D37': 'D1D17',\n",
    "         'D38': 'D3D17D1', 'D39': 'D3D6D5', 'D40': 'D17D1', 'D41': 'D7','D42': 'D13','D43': 'D13','D44': 'D13'}\n",
    "    \n",
    "def utterances(array, IDE):\n",
    "    sortedList = []\n",
    "    speaker = \"\"\n",
    "    for i in array:\n",
    "        if i[0] != speaker:\n",
    "            speaker = i[0]\n",
    "            sortedList.append([])\n",
    "        if IDE:\n",
    "            val = IDEMap[i[2]] if i[2] in IDEMap.keys() else i[2]\n",
    "            val = list(map(int, val.split('D')[1:]))\n",
    "            sortedList[-1].extend(val)\n",
    "        else:\n",
    "            val = list(map(int, i[1].split('S')[1:]))\n",
    "            sortedList[-1].append(val)\n",
    "    return sortedList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2574b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues, ides = [], []\n",
    "for i in files:\n",
    "    ides.append(utterances(i, IDE=True))\n",
    "    dialogues.append(utterances(i, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ed93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(array) :\n",
    "    inputs, outputs = [], []\n",
    "    for i in range(len(array)):\n",
    "        if i < len(array)-1:\n",
    "            inputs.append(array[i])\n",
    "            outputs.append(array[i+1])\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f748b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_input, dialogue_output = [],[]\n",
    "ide_input, ide_output = [], []\n",
    "\n",
    "for i in dialogues:\n",
    "    a, b = sort(i)\n",
    "    dialogue_input.append(a)\n",
    "    dialogue_output.append(b)\n",
    "\n",
    "for i in ides:\n",
    "    a, b = sort(i)\n",
    "    ide_input.append(a)\n",
    "    ide_output.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4832f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstUtterances(input_arr, output_arr):\n",
    "    input_data, output_data = [], []\n",
    "    for i in range(0, 9):\n",
    "        for j in range(len(input_arr[i])):\n",
    "            input_data.append(np.array(input_arr[i][j][0]))\n",
    "            output_data.append(np.array(output_arr[i][j][0]))\n",
    "    return np.array(input_data), np.array(output_data)\n",
    "\n",
    "def lastUtterances(input_arr, output_arr):\n",
    "    input_data, output_data = [], []\n",
    "    for i in range(0, 9):\n",
    "        for j in range(len(input_arr[i])):\n",
    "            input_data.append(np.array(input_arr[i][j][-1]))\n",
    "            output_data.append(np.array(output_arr[i][j][0]))\n",
    "    return np.array(input_data), np.array(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e61eb766",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = firstUtterances(ide_input, ide_output)\n",
    "d_a, d_b = firstUtterances(dialogue_input, dialogue_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a97a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "058327e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2]\n",
      " [ 1]\n",
      " [ 3]\n",
      " ...\n",
      " [15]\n",
      " [ 7]\n",
      " [ 1]]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "13/13 - 0s - loss: 45.0344 - accuracy: 0.2620 - 125ms/epoch - 10ms/step\n",
      "13/13 - 0s - loss: 44.5558 - accuracy: 0.2524 - 32ms/epoch - 2ms/step\n",
      "13/13 - 0s - loss: 52.4254 - accuracy: 0.3101 - 34ms/epoch - 3ms/step\n",
      "13/13 - 0s - loss: 64.6542 - accuracy: 0.2572 - 44ms/epoch - 3ms/step\n",
      "13/13 - 0s - loss: 59.6700 - accuracy: 0.2668 - 31ms/epoch - 2ms/step\n",
      "Cross-validated accuracy: 0.26971153616905214\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "#         tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1, activation='relu')\n",
    "    ])\n",
    "#     add f1 and/or loss function for the metric because of the state imbalance\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(model, X, y, k=5):\n",
    "    from sklearn.model_selection import KFold\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "    scores = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "#         y_train = y_train.reshape(-1)\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "        score = model.evaluate(X_test, y_test, verbose=2)\n",
    "        scores.append(score[1])\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "print(d_a)\n",
    "# Load the input data and one-hot encode it\n",
    "X = tf.keras.utils.to_categorical(d_a)\n",
    "y = np.array(d_b)\n",
    "print(X)\n",
    "model = build_model()\n",
    "score = train_and_evaluate_model(model, X, y)\n",
    "print(\"Cross-validated accuracy:\", score)\n",
    "\n",
    "# confusion matrix- tells you \n",
    "# hand validation - write code that takes one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fb8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900516a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047da32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
